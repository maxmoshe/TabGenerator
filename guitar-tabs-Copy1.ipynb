{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64cabc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 23:40:09.140191: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-22 23:40:09.140241: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "#Add running from cmd.\n",
    "\n",
    "SEQ_LEN = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9563be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_urls(query, pages=1, get_top_only=True):\n",
    "    urls = []\n",
    "    for page in range(1, pages+1):\n",
    "        url = f'https://www.ultimate-guitar.com/search.php?page={page}&title={query.replace(\" \", \"%20\")}&type=200'\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 404: return urls #finished iterating over all pages.\n",
    "        soup = BeautifulSoup(r.text)\n",
    "        j = soup.find(\"div\", {\"class\": \"js-store\"})['data-content']\n",
    "        tabs = json.loads(j)['store']['page']['data']['results']\n",
    "\n",
    "        song_id = 0\n",
    "        for tab in tabs:\n",
    "            if 'marketing_type' in tab: continue #ignore paid tabs.\n",
    "            if not get_top_only: urls.append(tab['tab_url']); continue\n",
    "            if song_id == 0: song_id, rating, url = tab['song_id'], tab['rating'], tab['tab_url']\n",
    "                \n",
    "            if song_id != tab['song_id']:\n",
    "                if rating > 3: #don't append bad tabs.\n",
    "                    urls.append(url)\n",
    "                    print(f'Best: {rating} - {url}')\n",
    "                song_id = tab['song_id']\n",
    "                rating = tab['rating']\n",
    "                url = tab['tab_url']\n",
    "\n",
    "            if tab['rating'] > rating:\n",
    "                rating = tab['rating']\n",
    "                url = tab['tab_url']\n",
    "                \n",
    "    return urls\n",
    "\n",
    "def get_urls_top(): #gets top 100 tabs.\n",
    "    urls = []\n",
    "    url = 'https://www.ultimate-guitar.com/top/tabs?order=hitsdailygroup_desc&type=tab'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    j = soup.find(\"div\", {\"class\": \"js-store\"})['data-content']\n",
    "    tabs = json.loads(j)['store']['page']['data']['tabs']#['results']\n",
    "    print(tabs)\n",
    "\n",
    "    for tab in tabs:\n",
    "        if 'marketing_type' in tab: continue #paid tabs.\n",
    "        urls.append(tab['tab_url'])\n",
    "    return urls\n",
    "\n",
    "#urls = get_urls('pink floyd', 10)\n",
    "#urls = get_urls_top(2)\n",
    "urls = []\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87511aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_tab(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    j = soup.body.find_all(\"div\")[2]['data-content']\n",
    "    text = json.loads(j)['store']['page']['data'][\"tab_view\"]['wiki_tab']['content']\n",
    "    return text\n",
    "\n",
    "for url in urls:\n",
    "    time.sleep(0.5) #spamming requests blocks you.\n",
    "    text = get_tab(url)\n",
    "    name = url.split('/')[-1]\n",
    "    with open(f\"tabs/{name}\", 'w') as f:\n",
    "        f.write(text)\n",
    "    print(f'{name} downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25534961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 12, 1, 1, 1, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2490/427577424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;31m#LSTM only accepts 3d data. seq/6/chars -> seq/6*chars.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seqs' is not defined"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "#Seperates tab from other notation\n",
    "def seperate_tabs(text):\n",
    "    tabs = []\n",
    "    count = 0\n",
    "    text = text.replace('[tab]', '').replace('[/tab]', '').replace(' ', '')\n",
    "    text_split = text.split('\\n')\n",
    "    for i, l in enumerate(text_split):\n",
    "        if len(l) < 10: count = 0; continue\n",
    "        if l[0] == '|' and l[1] in '-123456789(': #if string is not specified, label the correct string (assuming EADGBe)\n",
    "            if count == 6: return #Tabs are for 7+ strings. Disregard the tab.\n",
    "            string = 'eBGDAE'[count]\n",
    "            count += 1\n",
    "            l = string + l\n",
    "            \n",
    "        else: count = 0\n",
    "        \n",
    "        if l[0].lower() in 'ebgda' and l[1] == '|':\n",
    "            if l[0] == 'E' and i>0 and len(text_split[i-1])>0 and text_split[i-1][0] not in 'A|': l = 'e' + l[1:] #sometimes people label high e as E. lowercase it.\n",
    "            stripped_line = l.replace('|', '').replace('\\r', '').replace(' ', '')\n",
    "            tabs.append(stripped_line)\n",
    "    return tabs\n",
    "\n",
    "\n",
    "def pad_tabs(tabs):\n",
    "    longest = max([len(l) for l in tabs])\n",
    "    tabs = [l + '-' * (longest-len(l)) for l in tabs]\n",
    "    return tabs\n",
    "\n",
    "\n",
    "#Concatenates tabs by common string.\n",
    "def join_tabs(tabs):\n",
    "    strings = {}\n",
    "    for l in tabs:\n",
    "        if l[0] not in strings:\n",
    "            strings[l[0]] = ''\n",
    "            continue\n",
    "        strings[l[0]] += l[1:]\n",
    "    tab_list = list(strings.values())\n",
    "    tab_list = pad_tabs(tab_list)\n",
    "\n",
    "    return tab_list\n",
    "\n",
    "tab_dict = {'-': 1, '1': 2, '2': 3, '0': 4, '7': 5, '5': 6, '4': 7, '3': 8, '9': 9, 'x': 10, '6': 11, 'b': 12, '(': 13, ')': 14, '8': 15, '/': 16, '~': 17, 'p': 18, 'h': 19, '=': 20, '\\\\': 21, 's': 22, \"'\": 23, 'r': 24}\n",
    "seq_dict = {0: 'O', 1: '-', 2: '1', 3: '2', 4: '0', 5: '7', 6: '5', 7: '4', 8: '3', 9: '9', 10: 'x', 11: '6', 12: 'b', 13: '(', 14: ')', 15: '8', 16: '/', 17: '~', 18: 'p', 19: 'h', 20: '=', 21: '\\\\', 22: 's', 23: \"'\", 24: 'r'}\n",
    "\n",
    "\n",
    "text_to_seq = lambda text: [tab_dict.get(s.lower()) or 0 for s in text] #0 is out of vocab.\n",
    "seq_to_text = lambda seq: [seq_dict[n] for n in seq]\n",
    "\n",
    "def tab_to_seq(tab):\n",
    "    for i, s in enumerate(tab):\n",
    "        tab[i] = text_to_seq(s)\n",
    "    return tab\n",
    "\n",
    "\n",
    "def write_tab_binary(tab_list): #custom file format: byte = tab-char index, 6bytes = timestep.\n",
    "    with open('data', 'ab') as f:\n",
    "        for i in range(len(tab_list[0])):\n",
    "            binary = struct.pack('6B', tab_list[0][i], tab_list[1][i], tab_list[2][i], tab_list[3][i], tab_list[4][i], tab_list[5][i])\n",
    "            f.write(binary)\n",
    "        \n",
    "\n",
    "tab_lists = []\n",
    "for filename in glob.glob('tabs/*'):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "    tabs = seperate_tabs(text)\n",
    "    if not tabs: continue\n",
    "    tab_list = join_tabs(tabs)\n",
    "    if len(tab_list) != 6 or len(tab_list[0]) < SEQ_LEN+1: continue #if string_num isn't 6 or tab length is shorter than 1 sequence__lem, skip tab\n",
    "    tab_list = tab_to_seq(tab_list)\n",
    "    write_tab_binary(tab_list)\n",
    "    #tab_lists.append(tab_list)\n",
    "    \n",
    "    \n",
    "with open('data', 'rb') as f:\n",
    "    #for i in range(60):\n",
    "    d = f.read(6*SEQ_LEN)\n",
    "    print(struct.unpack(f'{6*SEQ_LEN}B', d)t)\n",
    "    #print(struct.unpack('BBBBBB', d))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# chars = sorted(list(set(concatenated))) #manually creating a dict is better.\n",
    "# char_dict = dict((c, i) for i, c in enumerate(chars))\n",
    "# reversed_char_dict = dict((i, c) for i, c in enumerate(chars))\n",
    "# tokenize_list = lambda s: [char_dict[c] for c in s]\n",
    "# detokenize_list = lambda s: [reversed_char_dict[n] for n in s]\n",
    "\n",
    "def one_hot(arr):\n",
    "    encoded = np.zeros((len(arr), len(char_dict)), dtype='bool') #uint8\n",
    "    for i, n in enumerate(arr):\n",
    "        encoded[i][n] = 1\n",
    "    return encoded\n",
    "    \n",
    "def create_seqs(arr, seq_len=SEQ_LEN):\n",
    "    seqs = []\n",
    "    for i in range(len(arr) - seq_len):\n",
    "        seqs.append(arr[i:i+seq_len])\n",
    "    return np.array(seqs)\n",
    "    \n",
    "#one-hot all the tabs.\n",
    "\n",
    "for i, tab in enumerate(tab_lists):\n",
    "    encoded_list = []\n",
    "    for s in tab:\n",
    "        encoded_list.append(one_hot(tokenize_list(s)))\n",
    "\n",
    "    #reshape 6/seq/chars -> seq/6/chars\n",
    "    encoded_list = np.array(encoded_list).swapaxes(0,1)\n",
    "    if i == 0:\n",
    "        seqs = create_seqs(encoded_list)\n",
    "        print(seqs.shape)\n",
    "        continue\n",
    "    seqs = np.concatenate([seqs, create_seqs(encoded_list)])\n",
    "#     seqs = create_seqs(encoded_list)\n",
    "#     with open('numpy_data.npy', 'ab') as f:\n",
    "#         np.save(f, seqs)\n",
    "#     print(seqs.shape)\n",
    "    print(seqs.shape)\n",
    "\n",
    "print(seqs.shape)\n",
    "#LSTM only accepts 3d data. seq/6/chars -> seq/6*chars.\n",
    "x = seqs[:, :-1]\n",
    "x = x.reshape(x.shape[0], x.shape[1], x.shape[2] * x.shape[3]) #SEQ_LEN/6*chars\n",
    "y = seqs[:, -1] #6/chars\n",
    "y = [np.array(y[:, i]) for i in range(6)]\n",
    "\n",
    "#np.save('data.npy', [x, y]) #most comfortable format to save in, also fastest and most lightweight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa38814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "model_input = layers.Input((SEQ_LEN-1, 6*len(char_dict)))\n",
    "\n",
    "m = layers.LSTM(64, return_sequences=True)(model_input)\n",
    "m = layers.LSTM(64)(m)\n",
    "m = layers.Dense(256)(m)\n",
    "m = layers.LeakyReLU(0.3)(m)\n",
    "out = layers.Dense(len(char_dict), activation='softmax')(m)\n",
    "out2 = layers.Dense(len(char_dict), activation='softmax')(m)\n",
    "out3 = layers.Dense(len(char_dict), activation='softmax')(m)\n",
    "out4 = layers.Dense(len(char_dict), activation='softmax')(m)\n",
    "out5 = layers.Dense(len(char_dict), activation='softmax')(m)\n",
    "out6 = layers.Dense(len(char_dict), activation='softmax')(m)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=model_input, outputs=[out,out2,out3,out4,out5,out6], name=\"tab_generator\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "model.fit(x, y, batch_size=64, epochs=5)#, validation_data=(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(x[16].reshape(1, x.shape[1], x.shape[2]))\n",
    "# for p in prediction:\n",
    "#     print(reversed_char_dict[np.argmax(p)])\n",
    "\n",
    "predictions = []\n",
    "data = x[191]\n",
    "for i in range(36):\n",
    "    prediction = model.predict(data.reshape(1, x.shape[1], x.shape[2])) #prediction shape: (6, 1 ,chars) 6* [[chars]]\n",
    "    text_prediction = [reversed_char_dict[np.argmax(s)] for s in prediction]\n",
    "    predictions.append(text_prediction)\n",
    "    prediction = np.array(prediction)\n",
    "    prediction = prediction.reshape(1, -1) #(1,6, chars) \n",
    "    data[:-1] = data[1:]; data[-1] = prediction\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "for i in range(6):\n",
    "    print(''.join(predictions[:, i]))\n",
    "        \n",
    "# for i in range(35): #generate n next words\n",
    "#     prediction = np.argmax(model.predict(test_data), axis=-1)\n",
    "    \n",
    "#     test_data = x[0]\n",
    "#     test_data[:-1] = test_data[1:];test_data[-1] = prediction[0] #queue-append prediction\n",
    "#     test_data = test_data.reshape(-1, SEQ_LENGTH)\n",
    "#     #print(prediction)\n",
    "#     print(tokenizer.sequences_to_texts([prediction]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f1bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
